{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Domain Document Partitioning - Coverage Index Calcualtion"
      ],
      "metadata": {
        "id": "hdFLUorLHZFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx pdfminer.six beautifulsoup4 nltk ipywidgets --quiet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhYjFw32KQlV",
        "outputId": "6010d731-307f-4ce7-d925-6108fc15e5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from docx import Document\n",
        "from pdfminer.high_level import extract_text\n",
        "from io import BytesIO\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "RFnSZlukK_lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zygN590mHVfc"
      },
      "outputs": [],
      "source": [
        "# Initialize the Porter Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Create a set with all the words in english language\n",
        "english_words = set()\n",
        "with open(\"words_alpha.txt\") as f:\n",
        "    for line in f:\n",
        "        english_words.add(line.strip().lower())\n",
        "\n",
        "# Function to clean and filter text\n",
        "def clean_text(text):\n",
        "    # Split into tokens using regex\n",
        "    tokens = re.findall(r'\\b[a-zA-Z]+\\b', text)\n",
        "\n",
        "    # Filter proper nouns (capitalized words that are not at the start of a sentence)\n",
        "    filtered_tokens = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        if i > 0 and token[0].isupper() and not tokens[i - 1].endswith(('.','?','!')):  # Likely a proper noun\n",
        "            continue  # Skip proper noun\n",
        "        elif token.lower() in english_words:  # Keep valid English words\n",
        "            filtered_tokens.append(token.lower())\n",
        "        else:\n",
        "            continue  # Keep other words\n",
        "        # Stem each token\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Function to extract text from a file (DOCX or PDF)\n",
        "def extract_text_from_file(file_path):\n",
        "    extension = file_path.split('.')[-1].lower()\n",
        "    with open(file_path, 'rb') as f:\n",
        "        file_content = f.read()\n",
        "\n",
        "    if extension in ['docx', 'doc']:\n",
        "        document = Document(BytesIO(file_content))\n",
        "        text = \"\\n\".join([para.text for para in document.paragraphs])\n",
        "    elif extension == 'pdf':\n",
        "        text = extract_text(BytesIO(file_content))\n",
        "    else:\n",
        "        text = \"\"\n",
        "    return \" \".join(clean_text(text))\n",
        "\n",
        "# Function to scrape text from a URL\n",
        "def scrape_text_from_url(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        paragraphs = soup.find_all('p')\n",
        "        text = \"\\n\".join([para.get_text() for para in paragraphs])\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to calculate the coverage index\n",
        "def calculate_coverage(requirement_text, domain_texts):\n",
        "    req_terms = set(requirement_text.split())\n",
        "    domain_terms = set()\n",
        "    for domain_text in domain_texts:\n",
        "        domain_terms.update(domain_text.split())\n",
        "\n",
        "    uncovered_words = req_terms - domain_terms\n",
        "    coverage = len(req_terms.intersection(domain_terms)) / len(req_terms) if req_terms else 0\n",
        "    return coverage, uncovered_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input requirement document\n",
        "req_file_path = \"\"\n",
        "try:\n",
        "    req_content = extract_text_from_file(req_file_path)\n",
        "    print(f\"Requirement document '{req_file_path}' loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading requirement document: {e}\")\n",
        "\n",
        "# Input domain files folder\n",
        "domain_folder = \"\"\n",
        "domain_texts_from_files = []\n",
        "\n",
        "if os.path.isdir(domain_folder):\n",
        "    print(\"\\nLoading domain texts from files...\")\n",
        "    for file_name in os.listdir(domain_folder):\n",
        "        file_path = os.path.join(domain_folder, file_name)\n",
        "        if file_name.lower().endswith(('.docx', '.pdf')):\n",
        "            try:\n",
        "                text = extract_text_from_file(file_path)\n",
        "                domain_texts_from_files.append(text)\n",
        "                print(f\"- Successfully loaded text from: {file_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"- Failed to read file '{file_name}': {e}\")\n",
        "else:\n",
        "    print(f\"\\nError: The folder '{domain_folder}' does not exist or is not accessible.\")\n",
        "\n",
        "# Input domain URLs\n",
        "domain_urls = [\n",
        "    \"https://example.com/page1\",\n",
        "    \"https://example.com/page2\"\n",
        "]\n",
        "\n",
        "# Scrape domain texts from URLs\n",
        "domain_texts_from_urls = [scrape_text_from_url(url) for url in domain_urls]\n",
        "\n",
        "# Combine all domain texts\n",
        "domain_texts = domain_texts_from_urls + domain_texts_from_files\n",
        "\n",
        "# Calculate coverage index and uncovered words\n",
        "if req_content and domain_texts:\n",
        "    coverage, uncovered_words = calculate_coverage(req_content, domain_texts)\n",
        "    print(f\"\\nCoverage Index: {coverage:.2f}\")\n",
        "    print(\"\\nWords not covered:\")\n",
        "    for word in uncovered_words:\n",
        "        print(f\"- {word}\")\n",
        "else:\n",
        "    print(\"\\nError: No valid requirement text or domain texts found for coverage calculation.\")\n"
      ],
      "metadata": {
        "id": "O6GKxRm3Mv0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Knowledge Base Creation"
      ],
      "metadata": {
        "id": "RmwT1X2AtFaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone[grpc] PyPDF2 openai --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYbeqoU2_H0K",
        "outputId": "31b32735-3ae1-4f9c-941c-7eed50c19cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/319.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/421.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m421.4/421.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import openai\n",
        "import pinecone\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pinecone import ServerlessSpec\n",
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "import PyPDF2\n",
        "\n",
        "# Set API keys\n",
        "OPENAI_API_KEY = \"\"\n",
        "PINECONE_API_KEY = \"\"\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "# Initialize Pinecone client\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# File paths (placeholders)\n",
        "REQUIREMENT_DOC_PATH = \"\"\n",
        "DOMAIN_DOC_FOLDERS = [\"dd_1\", \"dd_2\", \"dd_3\"]\n",
        "\n",
        "# Embedding model name\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "# Maximum chunk size to avoid exceeding model limits\n",
        "MAX_CHUNK_SIZE = 1000  # Adjust based on model token limits\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "id": "RT70eg6ztZer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read PDF function\n",
        "def read_document(file_path):\n",
        "    \"\"\"Reads text from a PDF file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, \"rb\") as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page_num, page in enumerate(reader.pages):\n",
        "                page_text = page.extract_text()\n",
        "                if page_text:\n",
        "                    text += page_text\n",
        "                else:\n",
        "                    print(f\"Warning: No text extracted from page {page_num + 1}\")\n",
        "            if not text:\n",
        "                print(\"Warning: No text extracted from the PDF.\")\n",
        "            return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF file: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def read_all_documents_in_folder(folder_path):\n",
        "    \"\"\"Reads and concatenates text from all documents in a folder.\"\"\"\n",
        "    all_text = \"\"\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            all_text += read_document(file_path) + \"\\n\"\n",
        "    return all_text\n",
        "\n",
        "\n",
        "def chunk_text(text, max_chunk_size=MAX_CHUNK_SIZE):\n",
        "    \"\"\"Splits text into smaller chunks by character count to fit within model constraints.\"\"\"\n",
        "    return [text[i:i + max_chunk_size] for i in range(0, len(text), max_chunk_size)]\n",
        "\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"Gets the embedding for a given text using OpenAI's API.\"\"\"\n",
        "    response = openai.embeddings.create(input=[text], model=EMBEDDING_MODEL)\n",
        "    return np.array(response.data[0].embedding, dtype=np.float32)\n",
        "\n",
        "def create_pinecone_index(index_name, embeddings, chunks, namespace):\n",
        "    \"\"\"Creates a Pinecone index and upserts embeddings along with the text.\"\"\"\n",
        "    batch_size = 100\n",
        "    dimension = embeddings.shape[1]\n",
        "\n",
        "    # Interact with the Pinecone index\n",
        "    index = pc.Index('requirement-index')\n",
        "\n",
        "    # Prepare data to upsert (embedding + text as metadata)\n",
        "    upsert_data = [(str(i), embedding.tolist(), {\"text\": chunks[i]}) for i, embedding in enumerate(embeddings)]\n",
        "\n",
        "    # Upsert the data in batches\n",
        "    for i in range(0, len(upsert_data), batch_size):\n",
        "        batch = upsert_data[i:i + batch_size]\n",
        "        index.upsert(vectors=batch, namespace=namespace)\n",
        "        print(f\"Upserted batch {i // batch_size + 1} of {len(upsert_data) // batch_size + 1} batches.\")\n",
        "\n",
        "    return index\n",
        "\n",
        "def build_knowledge_base(text, index_name, namespace):\n",
        "    \"\"\"Builds a Pinecone vector database for a given document text.\"\"\"\n",
        "    chunks = chunk_text(text)\n",
        "    embeddings = np.array([get_embedding(chunk) for chunk in chunks])\n",
        "    index = create_pinecone_index(index_name, embeddings, chunks, namespace)\n",
        "    return index, chunks"
      ],
      "metadata": {
        "id": "pwliGfXKMDBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Requirement Knowledge Base"
      ],
      "metadata": {
        "id": "K-y1I3F4tetc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build requirement knowledge base\n",
        "req_text = read_document(REQUIREMENT_DOC_PATH)"
      ],
      "metadata": {
        "id": "zGOGgF29zcUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "req_index_name = \"requirement-index\"\n",
        "req_index, req_chunks = build_knowledge_base(req_text, req_index_name, 'kb_r')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN1UtraVCdUJ",
        "outputId": "3f9c821b-3322-478a-e2ab-5493a142e698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upserted batch 1 of 1 batches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_list = pc.list_indexes()\n",
        "\n",
        "print(index_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kec_gK1hL8KF",
        "outputId": "26fd4e46-3c45-4d68-907d-dd07399fbe59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\n",
            "    \"name\": \"requirement-index\",\n",
            "    \"dimension\": 1536,\n",
            "    \"metric\": \"cosine\",\n",
            "    \"host\": \"requirement-index-41400d9.svc.aped-4627-b74a.pinecone.io\",\n",
            "    \"spec\": {\n",
            "        \"serverless\": {\n",
            "            \"cloud\": \"aws\",\n",
            "            \"region\": \"us-east-1\"\n",
            "        }\n",
            "    },\n",
            "    \"status\": {\n",
            "        \"ready\": true,\n",
            "        \"state\": \"Ready\"\n",
            "    },\n",
            "    \"deletion_protection\": \"disabled\"\n",
            "}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Domain Knowledge Bases"
      ],
      "metadata": {
        "id": "QKCLQcHYv3SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build domain knowledge bases\n",
        "domain_indices = []\n",
        "domain_chunks_list = []\n",
        "for i, folder in enumerate(DOMAIN_DOC_FOLDERS):\n",
        "    print(folder)\n",
        "    domain_text = read_all_documents_in_folder(folder)\n",
        "    domain_index_name = f\"domain-index-{i}\"\n",
        "    index, chunks = build_knowledge_base(domain_text, 'requirement-index', domain_index_name)\n",
        "    domain_indices.append(index)\n",
        "    domain_chunks_list.append(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaaXMn70T2kE",
        "outputId": "5f9a7038-1ee4-48a8-e5f8-6f38c31b6c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dd_1\n",
            "Warning: No text extracted from page 302\n",
            "Upserted batch 1 of 16 batches.\n",
            "Upserted batch 2 of 16 batches.\n",
            "Upserted batch 3 of 16 batches.\n",
            "Upserted batch 4 of 16 batches.\n",
            "Upserted batch 5 of 16 batches.\n",
            "Upserted batch 6 of 16 batches.\n",
            "Upserted batch 7 of 16 batches.\n",
            "Upserted batch 8 of 16 batches.\n",
            "Upserted batch 9 of 16 batches.\n",
            "Upserted batch 10 of 16 batches.\n",
            "Upserted batch 11 of 16 batches.\n",
            "Upserted batch 12 of 16 batches.\n",
            "Upserted batch 13 of 16 batches.\n",
            "Upserted batch 14 of 16 batches.\n",
            "Upserted batch 15 of 16 batches.\n",
            "Upserted batch 16 of 16 batches.\n",
            "dd_2\n",
            "Upserted batch 1 of 11 batches.\n",
            "Upserted batch 2 of 11 batches.\n",
            "Upserted batch 3 of 11 batches.\n",
            "Upserted batch 4 of 11 batches.\n",
            "Upserted batch 5 of 11 batches.\n",
            "Upserted batch 6 of 11 batches.\n",
            "Upserted batch 7 of 11 batches.\n",
            "Upserted batch 8 of 11 batches.\n",
            "Upserted batch 9 of 11 batches.\n",
            "Upserted batch 10 of 11 batches.\n",
            "Upserted batch 11 of 11 batches.\n",
            "dd_3\n",
            "Warning: No text extracted from page 20\n",
            "Upserted batch 1 of 14 batches.\n",
            "Upserted batch 2 of 14 batches.\n",
            "Upserted batch 3 of 14 batches.\n",
            "Upserted batch 4 of 14 batches.\n",
            "Upserted batch 5 of 14 batches.\n",
            "Upserted batch 6 of 14 batches.\n",
            "Upserted batch 7 of 14 batches.\n",
            "Upserted batch 8 of 14 batches.\n",
            "Upserted batch 9 of 14 batches.\n",
            "Upserted batch 10 of 14 batches.\n",
            "Upserted batch 11 of 14 batches.\n",
            "Upserted batch 12 of 14 batches.\n",
            "Upserted batch 13 of 14 batches.\n",
            "Upserted batch 14 of 14 batches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Elucidation Questions"
      ],
      "metadata": {
        "id": "9q7eB1nowXe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "import json\n",
        "\n",
        "def generate_elucidation_questions(requirement_text, comment_text):\n",
        "    \"\"\"Generates structured elucidation questions using JSON format for easier parsing.\"\"\"\n",
        "\n",
        "    # System message to enforce strict response format and task adherence\n",
        "    system_prompt = \"\"\"\n",
        "    The assistant strictly adheres to the user's instructions and tasks. The tasks given by the user will be challenging, so the assistant should pay close attention while solving the provided complex tasks. The assistant's response is always a JSON object and does not include any additional details.\n",
        "    \"\"\"\n",
        "\n",
        "    # User message providing input requirement and context\n",
        "    user_prompt = f\"\"\"\n",
        "    **Task:** Identify ambiguous terms within the given requirement statement. Generate elucidation questions to clarify these ambiguities and make the requirement more precise.\n",
        "\n",
        "    **Start of examples:**\n",
        "\n",
        "    **Example 1**\n",
        "    **Given requirement statement:** \"The system shall process user requests quickly.\"\n",
        "    **Given additional context:** \"Users should not experience noticeable delays.\"\n",
        "    **Expected Output (JSON):**\n",
        "    {{\n",
        "        \"Elucidations\": [\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"quickly\",\n",
        "                \"Elucidation Question\": \"What specific response time is expected for processing user requests?\"\n",
        "            }},\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"user requests\",\n",
        "                \"Elucidation Question\": \"What types of user requests need to be processed?\"\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "\n",
        "    ---\n",
        "\n",
        "    **Example 2**\n",
        "    **Given requirement statement:** \"The application shall support high-resolution images.\"\n",
        "    **Given additional context:** \"Users will upload various image formats.\"\n",
        "    **Expected Output (JSON):**\n",
        "    {{\n",
        "        \"Elucidations\": [\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"high-resolution\",\n",
        "                \"Elucidation Question\": \"What minimum resolution (in pixels) qualifies as 'high-resolution'?\"\n",
        "            }},\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"various image formats\",\n",
        "                \"Elucidation Question\": \"Which specific image formats should be supported?\"\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "\n",
        "    ---\n",
        "\n",
        "    **Example 3**\n",
        "    **Given requirement statement:** \"The system shall restrict access to sensitive data.\"\n",
        "    **Given additional context:** \"Only authorized users should view confidential information.\"\n",
        "    **Expected Output (JSON):**\n",
        "    {{\n",
        "        \"Elucidations\": [\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"restrict access\",\n",
        "                \"Elucidation Question\": \"What specific mechanisms will be used to enforce access restrictions?\"\n",
        "            }},\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"sensitive data\",\n",
        "                \"Elucidation Question\": \"Which categories of data are considered sensitive?\"\n",
        "            }},\n",
        "            {{\n",
        "                \"Ambiguous Term\": \"authorized users\",\n",
        "                \"Elucidation Question\": \"What criteria determine if a user is authorized?\"\n",
        "            }}\n",
        "        ]\n",
        "    }}\n",
        "\n",
        "    ---\n",
        "\n",
        "    **End of examples.**\n",
        "\n",
        "    Now provide your analysis in JSON with keys `\"Elucidations\"`, `\"Ambiguous Term\"`, and `\"Elucidation Question\"` for the following given requirement statement and context.\n",
        "\n",
        "    **Given requirement statement:** \"{requirement_text}\"\n",
        "\n",
        "    **Given additional context:** \"{comment_text}\"\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Call the model\n",
        "        response = client.chat.completions.create(\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            model=\"gpt-3.5-turbo\"\n",
        "        )\n",
        "\n",
        "        # Extract and parse the response as JSON\n",
        "        elucidation_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        try:\n",
        "            elucidation_data = json.loads(elucidation_text)\n",
        "            return elucidation_data.get(\"Elucidations\", [])  # Return list of elucidations\n",
        "        except json.JSONDecodeError:\n",
        "            print(f\"Warning: Could not parse JSON for requirement: {requirement_text}\")\n",
        "            return []  # Return empty list if JSON parsing fails\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing requirement: {requirement_text}\\n{e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def process_requirements(input_excel_path, output_excel_path):\n",
        "    \"\"\"Process the Excel file, generate structured elucidation questions, and save the result.\"\"\"\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(input_excel_path)\n",
        "\n",
        "    elucidations = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        requirement_text = row['Requirement']\n",
        "        comment_text = row.get('Comment', '')  # Get comment, default to empty string if missing\n",
        "\n",
        "        # Generate structured elucidation questions\n",
        "        elucidation_pairs = generate_elucidation_questions(requirement_text, comment_text)\n",
        "\n",
        "        # If no elucidations were found, still include the requirement with \"None\" values\n",
        "        if not elucidation_pairs:\n",
        "            elucidations.append({\n",
        "                'Requirement': requirement_text,\n",
        "                'Comment': comment_text,\n",
        "                'Ambiguous Term': \"None\",\n",
        "                'Elucidation Question': \"None\"\n",
        "            })\n",
        "        else:\n",
        "            for item in elucidation_pairs:\n",
        "                elucidations.append({\n",
        "                    'Requirement': requirement_text,\n",
        "                    'Comment': comment_text,\n",
        "                    'Ambiguous Term': item['Ambiguous Term'],\n",
        "                    'Elucidation Question': item['Elucidation Question']\n",
        "                })\n",
        "\n",
        "    # Create a new DataFrame with structured results\n",
        "    result_df = pd.DataFrame(elucidations)\n",
        "\n",
        "    # Save to a new Excel file\n",
        "    result_df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "# Example usage\n",
        "input_excel_path = \"/content/Requirements.xlsx\"\n",
        "output_excel_path = \"EQs.xlsx\"\n",
        "process_requirements(input_excel_path, output_excel_path)"
      ],
      "metadata": {
        "id": "Wrwshvamwo-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation Comparison and Pragmatic Ambiguity Detection"
      ],
      "metadata": {
        "id": "tLcSU6tnzNay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "import pinecone\n",
        "import regex as re\n",
        "\n",
        "# âœ… Initialize OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# âœ… Define Pinecone index\n",
        "INDEX_NAME = \"requirement-index\"\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "# âœ… Define namespaces and thresholds\n",
        "REQUIREMENT_NAMESPACE = \"kb_r\"\n",
        "DOMAIN_NAMESPACES = [\"domain-index-0\", \"domain-index-1\", \"domain-index-2\"]\n",
        "SIMILARITY_THRESHOLD = 0.85  # Pragmatic ambiguity detection threshold (between domain knowledge bases)\n",
        "REQ_SIMILARITY_THRESHOLD = 0.75  # Requirement KB similarity threshold\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"Generates an embedding for the given text using OpenAI API.\"\"\"\n",
        "    response = client.embeddings.create(input=[text], model=\"text-embedding-ada-002\")\n",
        "    return np.array(response.data[0].embedding, dtype=np.float32)\n",
        "\n",
        "def search_pinecone(query_embedding, namespace, top_k=3):\n",
        "    \"\"\"Searches Pinecone namespace for relevant text chunks and vectors.\"\"\"\n",
        "    results = index.query(\n",
        "        namespace=namespace,\n",
        "        vector=query_embedding.tolist(),\n",
        "        top_k=top_k,\n",
        "        include_metadata=True,\n",
        "        include_values=True\n",
        "    )\n",
        "\n",
        "    retrieved_texts = [match.metadata.get(\"text\", \"\").strip() for match in results.matches if \"text\" in match.metadata]\n",
        "    retrieved_vectors = [match.values for match in results.matches]\n",
        "\n",
        "    return retrieved_texts, retrieved_vectors\n",
        "\n",
        "def calculate_similarity(vec1, vec2):\n",
        "    \"\"\"Computes cosine similarity between two vectors.\"\"\"\n",
        "    return cosine_similarity(np.array(vec1).reshape(1, -1), np.array(vec2).reshape(1, -1))[0][0]\n",
        "\n",
        "def verify_answer_with_gpt(requirement_text, elucidation_question):\n",
        "    \"\"\"Checks if the requirement text answers the elucidation question.\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in requirements analysis. Given text from a requirement document and an elucidation question,\n",
        "    determine if the requirement text contains the answer to the question.\n",
        "\n",
        "    Requirement Text: \"{requirement_text}\"\n",
        "    Clarification Question: \"{elucidation_question}\"\n",
        "\n",
        "    Answer with ONLY \"YES\" or \"NO\". Do not provide any explanations.\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip().upper() == \"YES\"\n",
        "\n",
        "def process_clarifications(input_excel_path, output_excel_path):\n",
        "    \"\"\"Processes clarification questions grouped by requirement.\"\"\"\n",
        "    df = pd.read_excel(input_excel_path)\n",
        "    grouped_reqs = df.groupby(\"Requirement\")\n",
        "    results = []\n",
        "\n",
        "    for requirement_text, group in grouped_reqs:\n",
        "        is_ambiguous = False  # Default assumption: No ambiguity\n",
        "        answers_list = []\n",
        "        print(requirement_text)\n",
        "\n",
        "        for _, row in group.iterrows():\n",
        "            elucidation_question  = row[\"Elucidation Question\"]\n",
        "\n",
        "            # âœ… Skip empty elucidation questions\n",
        "            if pd.isna(elucidation_question) or elucidation_question.strip() == \"\":\n",
        "                continue\n",
        "\n",
        "            # âœ… Step 1: Generate embedding for the question\n",
        "            query_embedding = get_embedding(elucidation_question)\n",
        "\n",
        "            # âœ… Step 2: Search in Requirement KB\n",
        "            req_texts, requirement_vectors = search_pinecone(query_embedding, REQUIREMENT_NAMESPACE, top_k=3)\n",
        "\n",
        "            # âœ… Clean retrieved requirement texts\n",
        "            req_texts = [re.sub(r\"\\s+\", \" \", text).strip() for text in req_texts]\n",
        "\n",
        "            # âœ… Compute similarity scores for retrieved requirements\n",
        "            requirement_scores = [calculate_similarity(query_embedding, vec) for vec in requirement_vectors]\n",
        "\n",
        "            # âœ… Filter requirement texts that meet similarity threshold\n",
        "            above_threshold_texts = [req_texts[i] for i, score in enumerate(requirement_scores) if score >= REQ_SIMILARITY_THRESHOLD]\n",
        "\n",
        "            # âœ… Step 3: Verify with GPT if any requirement text contains the answer\n",
        "            gpt_says_answered = any(verify_answer_with_gpt(text, elucidation_question) for text in above_threshold_texts) if above_threshold_texts else False\n",
        "\n",
        "            if gpt_says_answered:\n",
        "                source = \"Requirement KB\"\n",
        "                answers = {\"domain-index-0\": \"N/A\", \"domain-index-1\": \"N/A\", \"domain-index-2\": \"N/A\"}\n",
        "                is_ambiguous = False  # No ambiguity if the requirement KB has the answer\n",
        "            else:\n",
        "                is_ambiguous = True  # Proceed to domain KB checks\n",
        "\n",
        "            # âœ… Step 4: Check across Domain KBs if ambiguity persists\n",
        "            if is_ambiguous:\n",
        "                domain_texts_dict = {\n",
        "                    ns: [re.sub(r\"\\s+\", \" \", text).strip() for text in search_pinecone(query_embedding, ns, top_k=3)[0]]\n",
        "                    for ns in DOMAIN_NAMESPACES\n",
        "                }\n",
        "                domain_vectors_dict = {ns: search_pinecone(query_embedding, ns, top_k=3)[1] for ns in DOMAIN_NAMESPACES}\n",
        "\n",
        "                # âœ… Step 5: Assume ambiguous by default\n",
        "                is_ambiguous = True\n",
        "                similarity_scores = []\n",
        "\n",
        "                # âœ… Step 6: Check similarity across all three namespaces\n",
        "                ns1, ns2, ns3 = DOMAIN_NAMESPACES  # Assuming exactly 3 namespaces\n",
        "                reference_vectors = []  # Store multiple reference vectors\n",
        "\n",
        "                # âœ… Compare top 3 vectors between ns1 and ns2 to find reference vectors\n",
        "                for vec1 in domain_vectors_dict[ns1][:3]:\n",
        "                    for vec2 in domain_vectors_dict[ns2][:3]:\n",
        "                        similarity = calculate_similarity(vec1, vec2)\n",
        "                        similarity_scores.append((ns1, ns2, similarity))\n",
        "\n",
        "                        if similarity >= SIMILARITY_THRESHOLD:\n",
        "                            reference_vectors.append(vec1)  # âœ… Store multiple reference vectors\n",
        "                    if reference_vectors:\n",
        "                        break\n",
        "\n",
        "                # âœ… Step 7: If reference vectors exist, check similarity in ns3\n",
        "                if reference_vectors:\n",
        "                    for vec3 in domain_vectors_dict[ns3][:3]:\n",
        "                        for ref_vec in reference_vectors:\n",
        "                            similarity = calculate_similarity(ref_vec, vec3)\n",
        "                            similarity_scores.append((ns1, ns3, similarity))\n",
        "\n",
        "                            if similarity >= SIMILARITY_THRESHOLD:\n",
        "                                is_ambiguous = False  # âœ… If ns3 is also similar, mark unambiguous\n",
        "                                break\n",
        "                        if not is_ambiguous:\n",
        "                            break\n",
        "\n",
        "            if is_ambiguous:\n",
        "                source = \"Domain KB\"\n",
        "\n",
        "            answers_list.append({\n",
        "                \"Requirement\": requirement_text,\n",
        "                \"Elucidation Question\": elucidation_question,\n",
        "                \"Pragmatic Ambiguity\": \"Yes\" if is_ambiguous else \"No\",\n",
        "                \"Source\": source,\n",
        "            })\n",
        "\n",
        "            if is_ambiguous:\n",
        "                break  # âœ… If one EQ is \"Yes\", stop processing further CQs for this requirement\n",
        "\n",
        "        # âœ… Mark all EQs for the same requirement as \"Yes\" if any one is \"Yes\"\n",
        "        if is_ambiguous:\n",
        "            for ans in answers_list:\n",
        "                ans[\"Pragmatic Ambiguity\"] = \"Yes\"\n",
        "\n",
        "        results.extend(answers_list)\n",
        "\n",
        "    # âœ… Save results to an Excel file\n",
        "    result_df = pd.DataFrame(results)\n",
        "    result_df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "# âœ… Example usage\n",
        "input_excel_path = \"EQs.xlsx\"\n",
        "output_excel_path = \"Answers.xlsx\"\n",
        "process_clarifications(input_excel_path, output_excel_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzw4wlFt2pv9",
        "outputId": "3b66940f-0c00-44fe-a809-e8916adec5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Clarus system shall be able to access in-situ environmental observations from data collectors.\n",
            "The Clarus system shall be able to access remotely sensed environmental observations from data collectors.\n",
            "The Clarus system shall be able to receive roadway weather measurements derived from VII data.\n",
            "The Clarus system shall calculate derived environmental data from observations.\n",
            "The Clarus system shall collect, quality control, and disseminate environmental data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation - Pragmatic Ambiguity Detection"
      ],
      "metadata": {
        "id": "vda7u8FFHe4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Load Ground Truth and Predicted Data\n",
        "ground_truth_path = \"ground_truth.xlsx\"\n",
        "predicted_path = \"answers.xlsx\"\n",
        "\n",
        "# Read Excel files\n",
        "ground_truth_df = pd.read_excel(ground_truth_path)\n",
        "predicted_df = pd.read_excel(predicted_path)\n",
        "\n",
        "# âœ… Find missing requirements\n",
        "missing_requirements = ground_truth_df[~ground_truth_df[\"Requirement\"].isin(predicted_df[\"Requirement\"])]\n",
        "\n",
        "# âœ… If there are missing requirements, add them with \"No\" label\n",
        "if not missing_requirements.empty:\n",
        "    print(f\"Adding {len(missing_requirements)} missing requirements to Answer Excel.\")\n",
        "\n",
        "    # Create new rows with Pragmatic Ambiguity set to \"No\"\n",
        "    missing_requirements = missing_requirements[[\"Requirement\"]].copy()\n",
        "    missing_requirements[\"Elucidation Question\"] = \"N/A\"\n",
        "    missing_requirements[\"Pragmatic Ambiguity\"] = \"No\"\n",
        "    missing_requirements[\"Source\"] = \"Not Evaluated\"\n",
        "\n",
        "    # Append missing requirements to predicted_df\n",
        "    predicted_df = pd.concat([predicted_df, missing_requirements], ignore_index=True)\n",
        "\n",
        "# âœ… Save the updated Answer Excel file\n",
        "updated_path = \"updated_answers.xlsx\"\n",
        "predicted_df.to_excel(updated_path, index=False)\n",
        "\n",
        "print(f\"Updated Answer Excel saved as: {updated_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLTYPQ-GKdNe",
        "outputId": "0641a1cd-6dd1-4fcf-c625-48289319fff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding 31 missing requirements to Answer Excel.\n",
            "Updated Answer Excel saved as: Updated_Answer_ChatGPT.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "# âœ… Convert \"Yes\"/\"No\" labels to binary format (1 = Ambiguous, 0 = Not Ambiguous)\n",
        "ground_truth_df[\"Pragmatic Ambiguity\"] = ground_truth_df[\"Pragmatic Ambiguity\"].map({\"Yes\": 1, \"No\": 0})\n",
        "predicted_df[\"Pragmatic Ambiguity\"] = predicted_df[\"Pragmatic Ambiguity\"].map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "# âœ… Aggregate predictions per requirement (If any CQ is \"Yes\", requirement is \"Yes\")\n",
        "predicted_agg = predicted_df.groupby(\"Requirement\", as_index=False)[\"Pragmatic Ambiguity\"].max()\n",
        "\n",
        "# âœ… Merge ground truth with aggregated predictions\n",
        "merged_df = ground_truth_df.merge(predicted_agg, on=\"Requirement\", how=\"left\", suffixes=(\"_true\", \"_pred\"))\n",
        "\n",
        "# âœ… Fix missing values in predictions by replacing NaN with \"No\" (0)\n",
        "merged_df[\"Pragmatic Ambiguity_pred\"].fillna(0, inplace=True)\n",
        "\n",
        "# âœ… Convert to integers (Ensure no NaN values)\n",
        "merged_df[\"Pragmatic Ambiguity_true\"] = merged_df[\"Pragmatic Ambiguity_true\"].astype(int)\n",
        "merged_df[\"Pragmatic Ambiguity_pred\"] = merged_df[\"Pragmatic Ambiguity_pred\"].astype(int)\n",
        "\n",
        "# âœ… Compute Confusion Matrix to get TP, TN, FP, FN\n",
        "tn, fp, fn, tp = confusion_matrix(\n",
        "    merged_df[\"Pragmatic Ambiguity_true\"],\n",
        "    merged_df[\"Pragmatic Ambiguity_pred\"]\n",
        ").ravel()\n",
        "\n",
        "# âœ… Ensure total count matches 140\n",
        "total_count = tn + fp + fn + tp\n",
        "assert total_count == len(merged_df), f\"Error: Total count {total_count} does not match 140!\"\n",
        "\n",
        "# âœ… Compute Precision, Recall, and F2-score using manual formulas\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "f2 = (5 * precision * recall) / ((4 * precision) + recall) if (precision + recall) > 0 else 0  # F2-score formula\n",
        "\n",
        "# âœ… Print results\n",
        "print(f\"Total Requirements: {len(merged_df)} (Should be 140)\")\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Positives (FP): {fp} (Model incorrectly marked ambiguous)\")\n",
        "print(f\"False Negatives (FN): {fn} (Model failed to detect ambiguity)\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F2 Score: {f2:.4f}\")\n",
        "\n",
        "# âœ… Extract FP and FN Requirements\n",
        "fp_requirements = merged_df[(merged_df[\"Pragmatic Ambiguity_true\"] == 0) & (merged_df[\"Pragmatic Ambiguity_pred\"] == 1)]\n",
        "fn_requirements = merged_df[(merged_df[\"Pragmatic Ambiguity_true\"] == 1) & (merged_df[\"Pragmatic Ambiguity_pred\"] == 0)]\n",
        "\n",
        "print(\"\\nðŸ”´ False Positives (FP) - Model Incorrectly Marked Ambiguous:\")\n",
        "print(fp_requirements[[\"Requirement\", \"Pragmatic Ambiguity_true\", \"Pragmatic Ambiguity_pred\"]])\n",
        "\n",
        "print(\"\\nðŸŸ  False Negatives (FN) - Model Failed to Detect Ambiguity:\")\n",
        "print(fn_requirements[[\"Requirement\", \"Pragmatic Ambiguity_true\", \"Pragmatic Ambiguity_pred\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO_UW-EyHgoV",
        "outputId": "a9d5a58e-049b-441d-f0df-63dc04d62e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Requirements: 140 (Should be 140)\n",
            "True Positives (TP): 41\n",
            "True Negatives (TN): 64\n",
            "False Positives (FP): 17 (Model incorrectly marked ambiguous)\n",
            "False Negatives (FN): 18 (Model failed to detect ambiguity)\n",
            "Precision: 0.7069\n",
            "Recall: 0.6949\n",
            "F2 Score: 0.6973\n",
            "\n",
            "ðŸ”´ False Positives (FP) - Model Incorrectly Marked Ambiguous:\n",
            "                                           Requirement  \\\n",
            "2    The Clarus system shall be able to access remo...   \n",
            "43   The Clarus system shall not require approval t...   \n",
            "48   The Clarus system shall accept data through a ...   \n",
            "49   The Clarus system shall be able to communicate...   \n",
            "52   The Clarus system shall be able to collect env...   \n",
            "61   The Clarus system shall provide a user interfa...   \n",
            "67   The Clarus system shall be able to operate on ...   \n",
            "73   All HTML coding shall meet FHWA requirements f...   \n",
            "75   The Clarus system shall be able to use latitud...   \n",
            "81   The Clarus system shall be able to publish env...   \n",
            "90   The Clarus system shall be able to support six...   \n",
            "95   The Clarus program shall provide an environmen...   \n",
            "98     The Clarus program shall provide setup support.   \n",
            "104  The Clarus program shall provide documentation...   \n",
            "113  The Clarus program shall operate according to ...   \n",
            "129  The Clarus system data definitions shall be co...   \n",
            "136  The Clarus system shall accept only observatio...   \n",
            "\n",
            "     Pragmatic Ambiguity_true  Pragmatic Ambiguity_pred  \n",
            "2                           0                         1  \n",
            "43                          0                         1  \n",
            "48                          0                         1  \n",
            "49                          0                         1  \n",
            "52                          0                         1  \n",
            "61                          0                         1  \n",
            "67                          0                         1  \n",
            "73                          0                         1  \n",
            "75                          0                         1  \n",
            "81                          0                         1  \n",
            "90                          0                         1  \n",
            "95                          0                         1  \n",
            "98                          0                         1  \n",
            "104                         0                         1  \n",
            "113                         0                         1  \n",
            "129                         0                         1  \n",
            "136                         0                         1  \n",
            "\n",
            "ðŸŸ  False Negatives (FN) - Model Failed to Detect Ambiguity:\n",
            "                                           Requirement  \\\n",
            "6    The Clarus system shall accept environmental d...   \n",
            "11   The Clarus system shall be able to retrieve en...   \n",
            "20   The Clarus system shall accept environmental d...   \n",
            "24   The Clarus system shall provide environmental ...   \n",
            "25   The Clarus system shall provide notification o...   \n",
            "46   The Clarus system shall record statistics abou...   \n",
            "47      The Clarus system shall log data transactions.   \n",
            "53   The Clarus system shall transfer data as effic...   \n",
            "65   The Clarus system shall use hardware that impl...   \n",
            "68   The Clarus system shall disseminate data in re...   \n",
            "72   The Clarus system shall disseminate data using...   \n",
            "79   The Clarus system shall be able to automatical...   \n",
            "82   The Clarus system shall be able to prioritize ...   \n",
            "85   The Clarus system shall be able to receive all...   \n",
            "96   The Clarus program shall provide an environmen...   \n",
            "117  Traffic management personnel shall be able to ...   \n",
            "124  The Clarus program shall maintain information ...   \n",
            "125  The Clarus program shall maintain information ...   \n",
            "\n",
            "     Pragmatic Ambiguity_true  Pragmatic Ambiguity_pred  \n",
            "6                           1                         0  \n",
            "11                          1                         0  \n",
            "20                          1                         0  \n",
            "24                          1                         0  \n",
            "25                          1                         0  \n",
            "46                          1                         0  \n",
            "47                          1                         0  \n",
            "53                          1                         0  \n",
            "65                          1                         0  \n",
            "68                          1                         0  \n",
            "72                          1                         0  \n",
            "79                          1                         0  \n",
            "82                          1                         0  \n",
            "85                          1                         0  \n",
            "96                          1                         0  \n",
            "117                         1                         0  \n",
            "124                         1                         0  \n",
            "125                         1                         0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-9a906dd83606>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  merged_df[\"Pragmatic Ambiguity_pred\"].fillna(0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pragmatic Ambiguity Resolution"
      ],
      "metadata": {
        "id": "IpvX2CNhdxT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "import pinecone\n",
        "import regex as re\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# âœ… Initialize OpenAI client\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "# âœ… Define Pinecone index\n",
        "INDEX_NAME = \"requirement-index\"\n",
        "index = pc.Index(INDEX_NAME)\n",
        "\n",
        "# âœ… Define namespaces\n",
        "REQUIREMENT_NAMESPACE = \"kb_r\"\n",
        "DOMAIN_NAMESPACES = [\"domain-index-0\", \"domain-index-1\", \"domain-index-2\"]\n",
        "TOP_K = 3  # Retrieve top 3 relevant chunks\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_embedding(text):\n",
        "    \"\"\"Generates an embedding for the given text using OpenAI API, ensuring valid inputs.\"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        raise ValueError(\"Invalid input: Text for embedding must be a non-empty string.\")\n",
        "\n",
        "    response = client.embeddings.create(input=[text], model=\"text-embedding-ada-002\")\n",
        "    embedding = np.array(response.data[0].embedding, dtype=np.float32)\n",
        "\n",
        "    # âœ… Check for NaN or Inf values\n",
        "    if not np.isfinite(embedding).all():\n",
        "        raise ValueError(f\"Embedding contains invalid values: {embedding}\")\n",
        "\n",
        "    return embedding\n",
        "\n",
        "def calculate_similarity(vec1, vec2):\n",
        "    \"\"\"Computes cosine similarity between two vectors.\"\"\"\n",
        "    return cosine_similarity(np.array(vec1).reshape(1, -1), np.array(vec2).reshape(1, -1))[0][0]\n",
        "\n",
        "def search_pinecone(query_embedding, namespace, top_k=3):\n",
        "    \"\"\"Searches Pinecone namespace for top-k relevant text chunks.\"\"\"\n",
        "    results = index.query(\n",
        "        namespace=namespace,\n",
        "        vector=query_embedding.tolist(),\n",
        "        top_k=top_k,\n",
        "        include_metadata=True,\n",
        "        include_values=False  # Only need metadata (text chunks)\n",
        "    )\n",
        "\n",
        "    retrieved_texts = [match.metadata.get(\"text\", \"\").strip() for match in results.matches if \"text\" in match.metadata]\n",
        "    return retrieved_texts\n",
        "\n",
        "def generate_resolution_with_gpt(requirement_text, elucidation_questions, req_chunks, domain_chunks):\n",
        "    \"\"\"Generates a final unambiguous requirement incorporating all suggested resolutions.\"\"\"\n",
        "\n",
        "    # System prompt to enforce strict adherence to instructions\n",
        "    system_prompt = \"\"\"\n",
        "    The assistant strictly adheres to the user's instructions and tasks. The tasks given by the user will be challenging,\n",
        "    so the assistant should pay close attention while solving the provided complex tasks. The assistant's response will\n",
        "    directly address the user's request without including any additional details.\n",
        "    \"\"\"\n",
        "\n",
        "    # User prompt with structured input\n",
        "    user_prompt = f\"\"\"\n",
        "    **Task**: Given the original requirement statement, elucidation questions, relevant requirement knowledge,\n",
        "    and relevant domain knowledge, rewrite the requirement to remove any ambiguities while preserving the original intent.\n",
        "\n",
        "    **Start of examples:**\n",
        "\n",
        "    **Example 1**\n",
        "    **Original Requirement**: \"The system shall process user requests quickly.\"\n",
        "    **Elucidation Questions**: \"What specific response time is expected for processing user requests?\"\n",
        "    **Relevant Requirement Knowledge**: \"Industry standards suggest response time under 2 seconds.\"\n",
        "    **Relevant Domain Knowledge**: \"User feedback indicates delays over 3 seconds cause frustration.\"\n",
        "    **Rewritten Requirement**: \"The system shall process user requests within 2 seconds to align with industry standards and user expectations.\"\n",
        "\n",
        "    **Example 2**\n",
        "    **Original Requirement**: \"The application shall support high-resolution images.\"\n",
        "    **Elucidation Questions**: \"What minimum resolution (in pixels) qualifies as 'high-resolution'?\"\n",
        "    **Relevant Requirement Knowledge**: \"Previous versions supported up to 1080p resolution.\"\n",
        "    **Relevant Domain Knowledge**: \"Competitor applications support resolutions up to 4K.\"\n",
        "    **Rewritten Requirement**: \"The application shall support images up to 4K resolution while maintaining compatibility with 1080p formats.\"\n",
        "\n",
        "    **Example 3**\n",
        "    **Original Requirement**: \"The system shall restrict access to sensitive data.\"\n",
        "    **Elucidation Questions**: \"What specific mechanisms will be used to enforce access restrictions?\"\n",
        "    **Relevant Requirement Knowledge**: \"Role-based access control (RBAC) is currently implemented.\"\n",
        "    **Relevant Domain Knowledge**: \"Regulatory guidelines require multi-factor authentication (MFA) for sensitive data.\"\n",
        "    **Rewritten Requirement**: \"The system shall restrict access to sensitive data using role-based access control (RBAC) and enforce multi-factor authentication (MFA) for compliance with regulatory guidelines.\"\n",
        "\n",
        "    **End of examples.**\n",
        "\n",
        "    Now provide your rewritten requirement for the following input:\n",
        "\n",
        "    **Original Requirement**: \"{requirement_text}\"\n",
        "\n",
        "    **Elucidation Questions**: \"{', '.join(elucidation_questions)}\"\n",
        "\n",
        "    **Relevant Requirement Knowledge**: \"{req_chunks}\"\n",
        "\n",
        "    **Relevant Domain Knowledge**: \"{domain_chunks}\"\n",
        "    \"\"\"\n",
        "\n",
        "    # Call the model\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "def process_resolutions(input_excel_path, output_excel_path, similarity_threshold=0.77):\n",
        "    \"\"\"Processes detected ambiguities and generates resolution suggestions only if similarity exceeds threshold.\"\"\"\n",
        "    df = pd.read_excel(input_excel_path)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Group all elucidation questions per requirement\n",
        "    grouped_reqs = df.groupby(\"Requirement\")[\"Elucidation Question\"].apply(list).reset_index()\n",
        "\n",
        "    for _, row in grouped_reqs.iterrows():\n",
        "        requirement_text = row[\"Requirement\"]\n",
        "        elucidation_questions = row[\"Elucidation Question\"]\n",
        "\n",
        "        if not elucidation_questions or all(pd.isna(q) or q.strip() == \"\" for q in elucidation_questions):\n",
        "            continue\n",
        "\n",
        "        # Generate embedding for the concatenated elucidation questions\n",
        "        combined_question_text = \" | \".join([q for q in elucidation_questions if isinstance(q, str) and q.strip()])\n",
        "        question_embedding = get_embedding(combined_question_text)\n",
        "\n",
        "        # Retrieve chunks & generate resolution for each Domain KB (only if similarity exceeds threshold)\n",
        "        domain_resolutions = {}\n",
        "        for namespace in DOMAIN_NAMESPACES:\n",
        "            domain_chunks = search_pinecone(question_embedding, namespace, top_k=TOP_K)\n",
        "            domain_chunks_str = \"\\n\".join(domain_chunks)\n",
        "\n",
        "            if domain_chunks:\n",
        "                domain_embedding = get_embedding(domain_chunks_str)\n",
        "                similarity = calculate_similarity(question_embedding, domain_embedding)\n",
        "\n",
        "                if similarity >= similarity_threshold:\n",
        "                    resolution = generate_resolution_with_gpt(requirement_text, elucidation_questions, domain_chunks_str)\n",
        "                else:\n",
        "                    resolution = \"\"  # Skip resolution generation if similarity is below the threshold\n",
        "            else:\n",
        "                resolution = \"\"\n",
        "\n",
        "            domain_resolutions[namespace] = resolution\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            \"ðŸ”¹ Requirement\": requirement_text,\n",
        "            \"ðŸ”¹ Elucidation Questions\": \" | \".join(elucidation_questions),\n",
        "            \"âœ… Resolution (Domain KB 1)\": domain_resolutions.get(\"domain-index-0\", \"\"),\n",
        "            \"âœ… Resolution (Domain KB 2)\": domain_resolutions.get(\"domain-index-1\", \"\"),\n",
        "            \"âœ… Resolution (Domain KB 3)\": domain_resolutions.get(\"domain-index-2\", \"\")\n",
        "        })\n",
        "\n",
        "    # Save results to an Excel file\n",
        "    result_df = pd.DataFrame(results)\n",
        "    result_df.to_excel(output_excel_path, index=False)\n",
        "\n",
        "# Example usage\n",
        "input_excel_path = \"EQs.xlsx\"\n",
        "output_excel_path = \"Candidate_resolutions.xlsx\"\n",
        "process_resolutions(input_excel_path, output_excel_path, similarity_threshold=0.77)\n"
      ],
      "metadata": {
        "id": "iYqK1o4rg9eT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}